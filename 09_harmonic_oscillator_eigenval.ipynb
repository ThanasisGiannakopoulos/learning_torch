{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86982787-0db1-4c75-a3bb-6cb6cdbce4a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e6a669e-6f03-4e63-a03f-2c6aee70a044",
   "metadata": {},
   "source": [
    "Solve the single harmonic oscillator ODE:\n",
    "$$\\, x_{tt} + \\omega^2 \\, x = 0$$     \n",
    "with initial conditions\n",
    "$$x(t=0)=A \\sin(\\phi) \\,, \\quad x(t=T)= A \\sin(\\omega T + \\phi)$$  \n",
    "where\n",
    "$$\\omega\\equiv \\sqrt{k/m}$$\n",
    "and the analytical solution is\n",
    "$$x(t) = A \\sin ( \\omega t + \\phi)$$\n",
    "with $A$ the oscillation amplitude and $\\phi$ the initial phase. Solve for $t \\in [0,T]$.\n",
    "\n",
    "Promote $\\omega$ to a trainable parameter.\n",
    "Give the following boundary conditions\n",
    "$$x(t=0) = c1 \\,, \\quad x(t=T) = c2$$\n",
    "and choose the constants $c1,c2$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4057fe1a-4702-49d6-a7bd-e52de6d89fbb",
   "metadata": {},
   "source": [
    "Define the neural network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "736d00b8-5ebd-4bd4-b689-e8bc50777f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "class model_1(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, width):\n",
    "        super(model_1,self).__init__()\n",
    "        self.in_layer = torch.nn.Linear(1,width) # in layer\n",
    "        self.hidden01 = torch.nn.Linear(width,width) # 1st hidden layer\n",
    "        self.hidden02 = torch.nn.Linear(width,width) # 2nd hidden layer \n",
    "        self.hidden03 = torch.nn.Linear(width,width) # 3rd hidden layer \n",
    "        self.out_layer = torch.nn.Linear(width,1) # out layer\n",
    "\n",
    "    def forward(self,t):\n",
    "        \n",
    "        # feed data in_layer\n",
    "        t = self.in_layer(t)\n",
    "        # activation function\n",
    "        t = torch.tanh(t)\n",
    "        # pass to the 1st hidden layer\n",
    "        t = self.hidden01(t)\n",
    "        # activation function\n",
    "        t = torch.tanh(t)\n",
    "        # pass to the 2st hidden layer\n",
    "        t = self.hidden02(t)\n",
    "        # pass to the 3st hidden layer\n",
    "        t = self.hidden03(t)\n",
    "        # activation function\n",
    "        t = torch.tanh(t)\n",
    "        # pass throught the out_layer\n",
    "        t = self.out_layer(t)\n",
    "        return t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d5ce9d1-f983-4cdf-883d-f718c57c40c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# copied from https://github.com/benmoseley/harmonic-oscillator-pinn/blob/main/Harmonic%20oscillator%20PINN.ipynb\n",
    "class FCN(torch.nn.Module):\n",
    "    \"Defines a connected network\"\n",
    "    \n",
    "    def __init__(self, N_INPUT, N_OUTPUT, N_HIDDEN, N_LAYERS):\n",
    "        super().__init__()\n",
    "        activation = torch.nn.Tanh\n",
    "        self.fcs = torch.nn.Sequential(*[\n",
    "                        torch.nn.Linear(N_INPUT, N_HIDDEN),\n",
    "                        activation()])\n",
    "        self.fch = torch.nn.Sequential(*[\n",
    "                        torch.nn.Sequential(*[\n",
    "                            torch.nn.Linear(N_HIDDEN, N_HIDDEN),\n",
    "                            activation()]) for _ in range(N_LAYERS-1)])\n",
    "        self.fce = torch.nn.Linear(N_HIDDEN, N_OUTPUT)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.fcs(x)\n",
    "        x = self.fch(x)\n",
    "        x = self.fce(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cdec093-e5ce-4f8b-a1f6-c355f18f2dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(torch.nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super(Model,self).__init__()\n",
    "        self.layer01 = torch.nn.Linear(1,10) # why 10?\n",
    "        self.layer02 = torch.nn.Linear(10,50)\n",
    "        self.layer03 = torch.nn.Linear(50,50)\n",
    "        self.layer04 = torch.nn.Linear(50,50)\n",
    "        self.layer05 = torch.nn.Linear(50,10)\n",
    "        self.layer06 = torch.nn.Linear(10,1) # why 10?\n",
    "    \n",
    "    def forward(self,t): # do they also need to be called x,t later?\n",
    "        inputs      = t#torch.cat([t], axis=1)\n",
    "        out_layer01 = torch.tanh(self.layer01(inputs))\n",
    "        out_layer02 = torch.tanh(self.layer02(out_layer01))\n",
    "        out_layer03 = torch.tanh(self.layer03(out_layer02))\n",
    "        out_layer04 = torch.tanh(self.layer04(out_layer03))\n",
    "        out_layer05 = torch.tanh(self.layer05(out_layer04))\n",
    "        out_layer06 = self.layer06(out_layer05) # self?\n",
    "        output      = out_layer06\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08efc761-05e0-42e0-8f60-95e877993a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "# set the model\n",
    "# model_1 has arguments (seld, width), but only count from width (tunable)\n",
    "model = FCN(1,1,32,3)\n",
    "#Model()\n",
    "#model_1(32)\n",
    "#FCN(1,1,32,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93840f3c-e40c-468d-a86f-a74a04e464d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# treat mu as a learnable parameter\n",
    "omega = torch.nn.Parameter(1*torch.ones(1, requires_grad=True))\n",
    "\n",
    "# optimizer and initialization of parameters (weights and biases)\n",
    "# add mu to the optimiser\n",
    "#optimizer = torch.optim.Adam(model.parameters(),lr=1.e-3)\n",
    "optimizer = torch.optim.Adam(list(model.parameters())+[omega],lr=5e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea3ca5f9-59f7-49ba-a640-409c266165bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# random (uniform) sample points\n",
    "def random_domain_points(tmax,n):\n",
    "    t = tmax*torch.rand((n,1), requires_grad=True)\n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac07d2f-2099-47b0-a646-94c24cc88b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# boundary conditions\n",
    "c1 = 1.0*torch.ones(1); # t=0\n",
    "c2 = 1.0*torch.ones(1); # t=tmax\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "199fea52-6be6-472f-8869-e9a442b7ef8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 500 # number of random sampling points\n",
    "\n",
    "epochs = 20000\n",
    "gamma1 = 1.0\n",
    "gamma2 = 1.0\n",
    "\n",
    "loss_list = []\n",
    "omegas = []\n",
    "\n",
    "for epoch in range(int(epochs)):\n",
    "    print('epoch = ', epoch, end='\\r')\n",
    "    optimizer.zero_grad() # to make the gradients zero\n",
    "    # t=0\n",
    "    t0 = torch.zeros(1, requires_grad=True)\n",
    "    # tmax\n",
    "    T = 10*torch.ones(1, requires_grad=True)\n",
    "    # time sample\n",
    "    t = random_domain_points(T, n)\n",
    "    x = model(t)\n",
    "    # Derivatives\n",
    "    x_t = torch.autograd.grad(outputs=x, \n",
    "                              inputs=t,\n",
    "                              create_graph=True,\n",
    "                              grad_outputs=torch.ones_like(x)\n",
    "                              )[0]\n",
    "    x_tt = torch.autograd.grad(outputs=x_t, \n",
    "                               inputs=t,\n",
    "                               create_graph=True,\n",
    "                               grad_outputs=torch.ones_like(x_t)\n",
    "                               )[0]\n",
    "    \n",
    "    # residual for the bulk of the domain\n",
    "    residual = x_tt + torch.pow(omega, 2)*x\n",
    "    loss_dom = torch.mean(torch.pow(residual,2))\n",
    "    # residual for initial data\n",
    "    # sol for x(t=0)\n",
    "    x0 = model(t0) # solution of x(t=0)\n",
    "    loss_x0 = torch.mean(torch.pow(x0 - c1, 2))\n",
    "    # sol for x(t=T)\n",
    "    xT = model(T) # solution of x(t=T)\n",
    "    loss_xT = torch.mean(torch.pow(xT - c2, 2))\n",
    "    # LOSS\n",
    "    loss = loss_dom + gamma1*loss_x0 + gamma2*loss_xT\n",
    "    # save loss and omega values\n",
    "    loss_list.append(loss.detach().numpy())\n",
    "    omegas.append(omega.item())\n",
    "    # detach() removes the \"requires_grad\" and numpy() makes it a numpy item to plot later\n",
    "    loss.backward() # This is for computing gradients using backward propagation\n",
    "    optimizer.step() # \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b0201f-613b-4809-801c-4197613b9dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.semilogy(loss_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1626046e-d9d5-4a68-a514-d2a3aefb4b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(omegas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0979045d-5e16-4294-8852-3529b5ff5d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the analytical solution\n",
    "def analytical_sol(omega, A, phi, t):\n",
    "    x = A*np.sin(omega*t + phi)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91444bb4-dadf-4265-a4ff-e19a763d4207",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the time domain; used to visualize the analytical solution\n",
    "T1 = 10 # tmax\n",
    "t = torch.linspace(0,T1,100)#.view(-1,10)\n",
    "#print(t)\n",
    "\n",
    "# the view(-1,1) make the row tensor to a column tensor\n",
    "# -1 means you dont know how many rows you need, and 1 mean that you want 1 element in each row\n",
    "t = torch.linspace(0,T1,100).view(-1,1)\n",
    "\n",
    "nn_sol = model(t).detach().numpy() # detach some extra info, and numpy makes a numpy array to plot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "697dd2a4-6d7f-4bc2-a0e0-04ca1c91cdea",
   "metadata": {},
   "outputs": [],
   "source": [
    "A1 = 1; # amplitude\n",
    "phi1 = 0.5*np.pi # initial phase\n",
    "\n",
    "an_sol = analytical_sol(1.885, A1, phi1, t)\n",
    "print(an_sol[-1])\n",
    "plt.figure()\n",
    "plt.plot(t, an_sol, label=\"analytical sol.\", lw=2)\n",
    "plt.plot(t, nn_sol, label=\"NN sol.\", lw=2, ls='--')\n",
    "plt.legend(loc='lower left')\n",
    "#plt.grid()\n",
    "#plt.xlim(t[0],t[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed98d4b9-1004-42d7-9208-ffc42bce818d",
   "metadata": {},
   "outputs": [],
   "source": [
    "omegas[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "820f5f10-922f-45ce-9436-f039e4558d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "A1 = 1; # amplitude\n",
    "phi1 = 0.5*np.pi # initial phase\n",
    "\n",
    "an_sol = analytical_sol(1*0.629, A1, phi1, t)\n",
    "print(an_sol[-1])\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(t, an_sol, label=\"analytical sol.\", lw=2)\n",
    "plt.legend(loc='lower left')\n",
    "#plt.grid()\n",
    "#plt.xlim(t[0],t[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de4b96c6-d196-4ba9-8fe2-ce5625df7577",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
